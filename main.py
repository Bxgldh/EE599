import warnings
warnings.filterwarnings("ignore")

# ==== åœ¨ä»»ä½•ç”¨åˆ° transformers ä¹‹å‰æ‰“è¡¥ä¸ ====
import transformers
from transformers.utils import import_utils

def _disable_torch_load_check(*args, **kwargs):
    # è¯¾ç¨‹é¡¹ç›®ç”¨çš„ä¸´æ—¶è¡¥ä¸ï¼šå…³é—­ torch>=2.6 å¼ºåˆ¶æ£€æŸ¥
    # æ³¨æ„åªåŠ è½½æ¥è‡ª HuggingFace å®˜æ–¹æˆ–å¯ä¿¡ä½œè€…çš„æƒé‡
    return

# 1) æ”¹ import_utils é‡Œçš„å®ç°
import_utils.check_torch_load_is_safe = _disable_torch_load_check

# 2) åŒæ—¶æ”¹ modeling_utils é‡Œæ‹¿åˆ°çš„åˆ«å
try:
    from transformers import modeling_utils
    if hasattr(modeling_utils, "check_torch_load_is_safe"):
        modeling_utils.check_torch_load_is_safe = _disable_torch_load_check
except Exception:
    # ä¸‡ä¸€ä¸åŒç‰ˆæœ¬å¯¼å…¥æ–¹å¼ä¸ä¸€æ ·ï¼Œè¿™é‡Œå°±é™é»˜è·³è¿‡
    pass

# 3) å…³é”®ï¼šæ”¹ trainer æ¨¡å—é‡Œçš„æœ¬åœ°å¼•ç”¨
try:
    import transformers.trainer as trainer_mod
    if hasattr(trainer_mod, "check_torch_load_is_safe"):
        trainer_mod.check_torch_load_is_safe = _disable_torch_load_check
except Exception:
    pass
# ==========================================

import argparse
from datetime import datetime
from pathlib import Path

import torch
from datasets import Dataset
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import AutoPeftModelForCausalLM, PeftModel

from configs import peft_config, training_arguments, CACHE_DIR, LLAMA_MODEL_NAME, FINBERT_DIR
from data_utils.dataset_build import load_and_split_data, build_clean_and_perturbed_test
from data_utils.evaluation import evaluate, compute_flip_rate, compute_sym_kl
from models.load_llama import load_llama
from models.predict_llama import predict
from training.sft_trainer import run_sft
from data_utils.match_sft_path import find_latest_sft_dir
from training.run_grpo_trl import run_grpo_trl


def main():
    # ======== 1ï¸âƒ£ å‚æ•°è§£æï¼šSFT / GRPO / GRPO-EVAL / baseline ========
    parser = argparse.ArgumentParser(description="Run sentiment classification pipeline")
    parser.add_argument("--run_sft", action="store_true", help="Run supervised fine-tuning (LoRA)")
    parser.add_argument("--run_grpo", action="store_true", help="Run GRPO fine-tuning (policy optimization)")
    parser.add_argument("--resume", action="store_true", help="Resume GRPO from checkpoint")
    parser.add_argument("--eval_grpo", action="store_true", help="Load latest GRPO model and evaluate only")

    args = parser.parse_args()

    # ======== 2ï¸âƒ£ baseline ç”¨çš„æ•°æ®ï¼ˆç»Ÿä¸€ cleanï¼‰========
    # baseline æˆ‘ä»¬å°±ç”¨å¹²å‡€æ•°æ®ï¼Œç®€å•æ¸…æ™°
    X_train, X_test, X_eval, y_true = load_and_split_data(
        "data/all-data.csv",
        perturb_data=False,   # âœ… baseline: clean only
    )
    print("Columns:", X_train.columns.tolist())
    train_data = Dataset.from_pandas(X_train)
    eval_data = Dataset.from_pandas(X_eval)

    # ============================================================
    #   3ï¸âƒ£ SFTï¼ˆæ°¸è¿œç”¨ clean data è®­ç»ƒï¼‰
    # ============================================================
    if args.run_sft:
        print("\n================ SFT (LoRA) MODE ================\n")
        print("ğŸ§¹ SFT training will use CLEAN training data only.\n")

        # SFT æ€»æ˜¯ç”¨ clean
        X_train_clean, X_test_clean, X_eval_clean, y_true_clean = load_and_split_data(
            "data/all-data.csv",
            perturb_data=False,
        )
        print("Columns (SFT X_train):", X_train_clean.columns.tolist())
        train_data = Dataset.from_pandas(X_train_clean)
        eval_data = Dataset.from_pandas(X_eval_clean)

        # SFT checkpoint å‘½åç»Ÿä¸€ç”¨ "clean"
        sft_mode_tag = "clean"

        # æŸ¥æ‰¾å·²æœ‰ CLEAN SFT checkpoint
        try:
            latest_sft_dir = find_latest_sft_dir(
                model_name=LLAMA_MODEL_NAME,
                mode_tag=sft_mode_tag,
                base_dir="./outputs/sft",
            )
            print(f"ğŸ§­ Found existing CLEAN SFT checkpoint: {latest_sft_dir}")
        except FileNotFoundError:
            latest_sft_dir = None
            print("ğŸ§­ No existing CLEAN SFT checkpoint found, will train a new one.\n")

        # === 3.1 è®­ç»ƒæˆ–å¤ç”¨ SFT ===
        model, tokenizer = load_llama(LLAMA_MODEL_NAME, CACHE_DIR)

        if latest_sft_dir is not None:
            print(f"âœ… Reusing CLEAN SFT checkpoint: {latest_sft_dir}")
            finetuned_model_dir = latest_sft_dir
        else:
            time_tag = datetime.now().strftime("%Y%m%d")
            sft_root = Path("./outputs/sft")
            sft_root.mkdir(parents=True, exist_ok=True)

            run_name = f"sft_{LLAMA_MODEL_NAME.split('/')[-1]}_{time_tag}_{sft_mode_tag}"
            sft_run_dir = sft_root / run_name

            training_arguments.output_dir = str(sft_run_dir)
            print(f"ğŸ“ SFT model will be saved to: {training_arguments.output_dir}\n")

            trainer = run_sft(
                model=model,
                tokenizer=tokenizer,
                train_data=train_data,
                eval_data=eval_data,
                training_args=training_arguments,
                peft_config=peft_config
            )
            trainer.train()
            trainer.save_model()
            tokenizer.save_pretrained(sft_run_dir)
            print("âœ… SFT training finished!\n")

            finetuned_model_dir = str(sft_run_dir)

        # === 3.2 åŠ è½½ SFT LoRA æ¨¡å‹å¹¶ merge ===
        print("â†’ Loading fine-tuned LoRA model for evaluation...")
        compute_dtype = torch.float16
        print("å¾®è°ƒæ¨¡å‹ä½ç½®ï¼š" + finetuned_model_dir)

        tokenizer = AutoTokenizer.from_pretrained(
            LLAMA_MODEL_NAME,
            cache_dir=CACHE_DIR,
            local_files_only=True,
            use_fast=True,
            trust_remote_code=True,
        )

        model = AutoPeftModelForCausalLM.from_pretrained(
            finetuned_model_dir,
            torch_dtype=compute_dtype,
            return_dict=True,
            low_cpu_mem_usage=True,
            device_map="auto",
        )

        merged_model = model.merge_and_unload()

        time_tag = datetime.now().strftime("%Y%m%d")
        merged_root = Path("./outputs/merged")
        merged_root.mkdir(parents=True, exist_ok=True)
        merged_run_dir = merged_root / f"merged_{LLAMA_MODEL_NAME.split('/')[-1]}_{time_tag}_{sft_mode_tag}"

        merged_model.save_pretrained(
            merged_run_dir,
            safe_serialization=True,
            max_shard_size="2GB"
        )
        tokenizer.save_pretrained(merged_run_dir)

        print(f"ğŸ“ Merged model saved to: {merged_run_dir}")

        # === 3.3 SFTï¼šåœ¨ CLEAN test ä¸Šè¯„ä¼° ===
        print("\nâ†’ [SFT] Evaluating on CLEAN test set ...")
        # preds_clean = predict(X_test_clean, merged_model, tokenizer)
        preds_clean, probs_clean = predict(X_test_clean_eval, grpo_model, grpo_tokenizer, return_probs=True)
        print("ğŸ”¹ [SFT | CLEAN] Metrics:")
        evaluate(y_true_clean, preds_clean)

        # === 3.4 SFTï¼šåœ¨ PERTURBED test ä¸Šè¯„ä¼° ===
        print("\nâ†’ [SFT] Building CLEAN + PERTURBED test sets for robustness eval ...")
        X_test_clean2, y_true_clean2, X_test_pert, y_true_pert = build_clean_and_perturbed_test(
            "data/all-data.csv"
        )

        print("â†’ [SFT] Evaluating on PERTURBED test set ...")
        # preds_pert = predict(X_test_pert, merged_model, tokenizer)
        preds_pert, probs_pert = predict(X_test_clean_eval, grpo_model, grpo_tokenizer, return_probs=True)
        print("ğŸ”¹ [SFT | PERTURBED] Metrics:")
        evaluate(y_true_pert, preds_pert)

        flip_rate = compute_flip_rate(preds_clean, preds_pert)
        sym_kl = compute_sym_kl(probs_clean, probs_pert)

        print(f"ğŸ”¸ Flip Rate (clean vs perturbed): {flip_rate:.4f}")
        print(f"ğŸ”¸ Symmetric KL (clean vs perturbed): {sym_kl:.4f}")

        return  # ç»“æŸ SFT æ¨¡å¼

    # ============================================================
    #   4ï¸âƒ£ GRPO è®­ç»ƒï¼ˆè®­ç»ƒæ—¶å¿…é¡»ç”¨ perturbï¼‰
    # ============================================================
    if args.run_grpo:
        print("\n================ GRPO MODE ================\n")
        print("ğŸ§ª GRPO training will use PERTURBED data (plus clean) for robustness rewards.\n")

        # 1ï¸âƒ£ æ‰¾ CLEAN SFT checkpointï¼ˆGRPO çš„èµ·ç‚¹ï¼‰
        sft_mode_tag = "clean"
        try:
            latest_sft_dir = find_latest_sft_dir(
                model_name=LLAMA_MODEL_NAME,
                mode_tag=sft_mode_tag,
                base_dir="./outputs/sft",
            )
            print(f"ğŸ§­ Using CLEAN SFT checkpoint for GRPO init: {latest_sft_dir}")
        except FileNotFoundError:
            raise RuntimeError(
                "No CLEAN SFT checkpoint found. Please run with --run_sft first."
            )

        # 2ï¸âƒ£ GRPO è¾“å‡ºç›®å½•ï¼ˆæŒ‰æ—¥æœŸï¼‰
        time_tag = datetime.now().strftime("%Y%m%d")
        grpo_root = Path("./outputs/grpo")
        grpo_root.mkdir(parents=True, exist_ok=True)
        grpo_run_dir = grpo_root / f"grpo_{LLAMA_MODEL_NAME.split('/')[-1]}_{time_tag}"
        print(f"â†’ [GRPO] Output dir: {grpo_run_dir}")

        w_gt = 0.0
        w_fin = 0.2
        w_cons = 0.3
        w_sft_kl = 0.0


        # 3ï¸âƒ£ è°ƒç”¨ GRPO è®­ç»ƒï¼ˆå†…éƒ¨å¤„ç† resume / saveï¼‰
        print("â†’ [GRPO] Training with perturb_data=True (using clean+perturbed pairs)...")
        trainer = run_grpo_trl(
            data_path="data/all-data.csv",
            sft_lora_path=latest_sft_dir,  # èµ·ç‚¹ = clean-SFT
            base_model_path=LLAMA_MODEL_NAME,
            cache_dir=CACHE_DIR,
            output_dir=str(grpo_run_dir),
            perturb_data=True,  # å¹²å‡€ + æ‰°åŠ¨ æˆå¯¹æ•°æ®
            use_finbert=True,
            finbert_model_name="ProsusAI/finbert",
            w_gt=w_gt,
            w_fin=w_fin,
            w_cons=w_cons,
            w_sft_kl=w_sft_kl,  # ç°åœ¨å…ˆå…¨éƒ¨ 0ï¼Œæ’é™¤ reward å½±å“
            resume=args.resume,
        )

        print("\n================ GRPO Hyperparameters ================")
        print(f"  w_gt      = {w_gt}")
        print(f"  w_fin     = {w_fin}")
        print(f"  w_cons    = {w_cons}")
        print(f"  w_sft_kl  = {w_sft_kl}")
        print("======================================================\n")

        print(f"\nâœ… GRPO fine-tuning done. Output saved to: {grpo_run_dir}\n")

        # 4ï¸âƒ£ è®­ç»ƒç”¨å®Œå°±æŠŠ trainer/model é‡Šæ”¾æ‰ï¼Œé˜²æ­¢æ˜¾å­˜ & çŠ¶æ€å½±å“
        del trainer
        try:
            torch.cuda.empty_cache()
        except Exception:
            pass

        # 5ï¸âƒ£ åƒ SFT eval ä¸€æ ·é‡æ–°åŠ è½½ base LLaMA + tokenizer
        print("â†’ [GRPO] Reloading base model + tokenizer for eval (aligned with SFT eval)...")
        base_model, grpo_tokenizer = load_llama(LLAMA_MODEL_NAME, CACHE_DIR)
        # load_llama é‡Œå·²ç»ï¼š
        # - ç”¨ BitsAndBytes 4bit + nf4
        # - è®¾ç½® pad_token / padding_side
        # - setup_chat_format(model, tokenizer)

        # 6ï¸âƒ£ æŒ‚è½½ GRPO LoRA adapter
        print("â†’ [GRPO] Attaching GRPO LoRA adapter for eval ...")
        grpo_model = PeftModel.from_pretrained(
            base_model,
            grpo_run_dir,
            is_trainable=False,
        )
        grpo_model.eval()
        print("âœ… GRPO eval model loaded.\n")

        # 7ï¸âƒ£ CLEAN + PERTURBED è¯„ä¼°ï¼ˆå®Œå…¨å¤ç”¨ SFT é‚£å¥— predict / evaluateï¼‰
        print("\nâ†’ [GRPO] Building CLEAN + PERTURBED test sets for robustness eval ...")
        X_test_clean_eval, y_true_clean_eval, X_test_pert_eval, y_true_pert_eval = build_clean_and_perturbed_test(
            "data/all-data.csv"
        )

        print("â†’ [GRPO-EVAL] Evaluating CLEAN test set ...")
        preds_clean, probs_clean = predict(X_test_clean_eval, grpo_model, grpo_tokenizer, return_probs=True)
        print("ğŸ”¹ [GRPO-EVAL | CLEAN] Metrics:")
        evaluate(y_true_clean_eval, preds_clean)

        print("\nâ†’ [GRPO-EVAL] Evaluating PERTURBED test set ...")
        preds_pert, probs_pert = predict(X_test_pert_eval, grpo_model, grpo_tokenizer, return_probs=True)
        print("ğŸ”¹ [GRPO-EVAL | PERTURBED] Metrics:")
        evaluate(y_true_pert_eval, preds_pert)

        flip_rate = compute_flip_rate(preds_clean, preds_pert)
        sym_kl = compute_sym_kl(probs_clean, probs_pert)

        print(f"ğŸ”¸ Flip Rate (clean vs perturbed): {flip_rate:.4f}")
        print(f"ğŸ”¸ Symmetric KL (clean vs perturbed): {sym_kl:.4f}")

        return  # ç»“æŸ GRPO è®­ç»ƒæ¨¡å¼

    # ============================================================
    #   5ï¸âƒ£ åªè¯„ä¼° GRPOï¼ˆä¸è®­ç»ƒï¼Œç”¨æœ€æ–°ä¸€æ¬¡ GRPOï¼‰
    # ============================================================
    if args.eval_grpo:
        print("\n================ GRPO EVAL MODE ================\n")

        grpo_root = Path("./outputs/grpo")
        if not grpo_root.exists():
            raise RuntimeError("No GRPO outputs found in ./outputs/grpo. Please run --run_grpo first.")

        grpo_runs = sorted(grpo_root.glob("grpo_*"))
        if not grpo_runs:
            raise RuntimeError("No GRPO run directories found. Please run --run_grpo first.")

        # æœ€æ–°ä¸€æ¬¡å®éªŒ
        latest_grpo_dir = grpo_runs[-1]
        grpo_run_dir = str(latest_grpo_dir)
        print(f"ğŸ“‚ Using latest GRPO dir: {grpo_run_dir}")

        # 1ï¸âƒ£ å’Œ SFT / Baseline å®Œå…¨ä¸€æ ·ï¼šç”¨ load_llama é‡æ–°åŠ è½½ base + tokenizer
        print("â†’ [GRPO-EVAL] Reloading base model + tokenizer (aligned with SFT eval)...")
        base_model, tokenizer = load_llama(LLAMA_MODEL_NAME, CACHE_DIR)
        # load_llama é‡Œé¢å·²ç»ï¼š
        #   - ç”¨ BitsAndBytes 4bit + nf4
        #   - è®¾ç½® pad_token / padding_side
        #   - setup_chat_format(model, tokenizer)

        # 2ï¸âƒ£ æŒ‚è½½ GRPO LoRA adapter
        print("â†’ [GRPO-EVAL] Attaching GRPO LoRA adapter...")
        grpo_model = PeftModel.from_pretrained(
            base_model,
            grpo_run_dir,
            is_trainable=False,
        )
        grpo_model.eval()
        print("âœ… GRPO eval model loaded.\n")

        # 3ï¸âƒ£ CLEAN / PERTURBED è¯„ä¼°ï¼ˆå¤ç”¨å’Œ SFT ä¸€æ ·çš„ pipelineï¼‰
        print("â†’ [GRPO-EVAL] Building CLEAN + PERTURBED test sets ...")
        X_test_clean_eval, y_true_clean_eval, X_test_pert_eval, y_true_pert_eval = build_clean_and_perturbed_test(
            "data/all-data.csv"
        )

        print("â†’ [GRPO-EVAL] Evaluating CLEAN test set ...")
        preds_clean, probs_clean = predict(X_test_clean_eval, grpo_model, tokenizer, return_probs=True)
        print("ğŸ”¹ [GRPO-EVAL | CLEAN] Metrics:")
        evaluate(y_true_clean_eval, preds_clean)

        print("\nâ†’ [GRPO-EVAL] Evaluating PERTURBED test set ...")
        preds_pert, probs_pert = predict(X_test_pert_eval, grpo_model, tokenizer, return_probs=True)
        print("ğŸ”¹ [GRPO-EVAL | PERTURBED] Metrics:")
        evaluate(y_true_pert_eval, preds_pert)

        flip_rate = compute_flip_rate(preds_clean, preds_pert)
        sym_kl = compute_sym_kl(probs_clean, probs_pert)

        print(f"ğŸ”¸ Flip Rate (clean vs perturbed): {flip_rate:.4f}")
        print(f"ğŸ”¸ Symmetric KL (clean vs perturbed): {sym_kl:.4f}")

        print("\nğŸ‰ GRPO Evaluation Finished.\n")
        return  # ç»“æŸ GRPO è¯„ä¼°æ¨¡å¼

    # ============================================================
    #   6ï¸âƒ£ Baselineï¼ˆä¿æŒç®€å•ï¼šclean è®­ç»ƒ + clean testï¼‰
    # ============================================================
    print("\n================ BASELINE MODE ================\n")
    print("ğŸ§¹ Baseline uses CLEAN training data only.\n")
    model, tokenizer = load_llama(LLAMA_MODEL_NAME, CACHE_DIR)
    preds = predict(X_test, model, tokenizer)
    print("ğŸ”¹ [Baseline | CLEAN] Metrics:")
    evaluate(y_true, preds)
    print("\nâœ… Baseline evaluation complete.\n")



if __name__ == "__main__":
    main()
