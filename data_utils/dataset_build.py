import os
import copy
import pandas as pd
from sklearn.model_selection import train_test_split
from data_utils.prompts import generate_prompt, generate_test_prompt
from data_perturbation import save_perturbation_text_pairs


def load_split_raw_data(
    path,
    train_size=300,
    test_size=300,
    seed=42,
    perturb_data=True,
):
    """
    ä» CSV åŠ è½½åŸå§‹æ•°æ®ï¼Œå¹¶æŒ‰ç±»åˆ«åˆ’åˆ† train/test/evalã€‚

    è¿”å›ï¼š
        X_train: DataFrameï¼Œè‡³å°‘åŒ…å«åˆ—ï¼š
                 - text       : è®­ç»ƒæ—¶ç”¨çš„æ–‡æœ¬ï¼ˆclean æˆ– perturb åçš„ï¼‰
                 - sentiment  : æ ‡ç­¾
                 - orig_text  : åŸå§‹ clean æ–‡æœ¬
                 - pert_text  : å¯¹åº”çš„æ‰°åŠ¨æ–‡æœ¬ï¼ˆè‹¥æœªæ‰°åŠ¨åˆ™ä¸ orig_text ç›¸åŒï¼‰

        X_test:  DataFrameï¼Œåˆ—ï¼š
                 - sentiment
                 - text       ï¼ˆåŸå§‹ clean æ–‡æœ¬ï¼‰

        X_eval:  DataFrameï¼Œåˆ—ï¼š
                 - sentiment
                 - text       ï¼ˆåŸå§‹ clean æ–‡æœ¬ï¼‰
    """
    # 1. è¯»åŸå§‹ CSV
    df = pd.read_csv(
        path,
        names=["sentiment", "text"],
        encoding="utf-8",
        encoding_errors="replace"
    )

    X_train = []
    X_test = []

    # 2. æŒ‰ç±»åˆ« stratified é‡‡æ · train/test
    for sentiment in ["positive", "neutral", "negative"]:
        train, test = train_test_split(
            df[df.sentiment == sentiment],
            train_size=train_size,
            test_size=test_size,
            random_state=seed,
        )
        X_train.append(train)
        X_test.append(test)

    X_train = pd.concat(X_train).sample(frac=1, random_state=10)
    X_test = pd.concat(X_test)

    # 3. æ„é€  eval é›†ï¼šå‰©ä¸‹çš„æ ·æœ¬é‡Œï¼Œæ¯ç±»é‡‡æ · 50 æ¡
    eval_idx = [idx for idx in df.index if idx not in list(X_train.index) + list(X_test.index)]
    X_eval = df[df.index.isin(eval_idx)]
    X_eval = (
        X_eval.groupby("sentiment", group_keys=False)
        .apply(lambda x: x.sample(n=50, random_state=10, replace=True))
    )

    # é‡ç½®ç´¢å¼•
    X_train = X_train.reset_index(drop=True)
    X_test = X_test.reset_index(drop=True)
    X_eval = X_eval.reset_index(drop=True)

    # 4. è®­ç»ƒé›†ï¼šæ˜¯å¦åšæ‰°åŠ¨æ‰©å¢
    if perturb_data:
        # æ·±æ‹·è´ï¼Œé¿å…æ±¡æŸ“åŸ df
        X_train_new = copy.deepcopy(X_train)

        # ---- åŸå§‹å¹²å‡€æ ·æœ¬ ----
        train_clean = X_train_new[["text", "sentiment"]].copy()
        train_clean["orig_text"] = train_clean["text"]
        train_clean["pert_text"] = train_clean["text"]

        # ---- æ„å»ºæ‰°åŠ¨å¯¹ ----
        headlines = X_train_new["text"].astype(str).tolist()

        if not os.path.exists("./data/train_perturbations_text_pairs.csv"):
            save_perturbation_text_pairs(
                headlines,
                filename="train_perturbations_text_pairs.csv"
            )

        pert_df = pd.read_csv("./data/train_perturbations_text_pairs.csv")
        # æœŸæœ›åˆ—: ["orig", "pert"]

        # ç”¨åŸå§‹ X_train_new çš„æ ‡ç­¾æ˜ å°„ç»™ orig
        label_map = dict(zip(X_train_new["text"], X_train_new["sentiment"]))
        pert_df["sentiment"] = pert_df["orig"].map(label_map)

        # ---- æ‰°åŠ¨æ ·æœ¬éƒ¨åˆ† ----
        train_aug = pert_df.rename(columns={"pert": "text"})[
            ["text", "sentiment", "orig"]
        ].copy()
        train_aug = train_aug.rename(columns={"orig": "orig_text"})
        train_aug["pert_text"] = train_aug["text"]

        # ---- åˆå¹¶å¹²å‡€æ ·æœ¬ + æ‰°åŠ¨æ ·æœ¬ ----
        X_train = pd.concat([train_clean, train_aug], ignore_index=True)
    else:
        # ä¸åšæ‰°åŠ¨æ‰©å¢ï¼Œä½†ä¹Ÿè¡¥ä¸Š orig_text / pert_textï¼Œä¾¿äº GRPO ç»Ÿä¸€å¤„ç†
        X_train = X_train.copy()
        X_train["orig_text"] = X_train["text"]
        X_train["pert_text"] = X_train["text"]

    return X_train, X_test, X_eval


def load_and_split_data(path, train_size=300, test_size=300, seed=42, perturb_data=True):
    X_train, X_test, X_eval = load_split_raw_data(
        path,
        train_size=train_size,
        test_size=test_size,
        seed=seed,
        perturb_data=perturb_data,
    )

    # ===== ä¸‹é¢æ˜¯ SFT / baseline ä¸“ç”¨çš„ prompt åŒ– =====
    X_train_prompt = pd.DataFrame(
        X_train.apply(generate_prompt, axis=1),
        columns=["text"]
    )
    X_eval_prompt = pd.DataFrame(
        X_eval.apply(generate_prompt, axis=1),
        columns=["text"]
    )

    y_true = X_test["sentiment"]
    X_test_prompt = pd.DataFrame(
        X_test.apply(generate_test_prompt, axis=1),
        columns=["text"]
    )

    return X_train_prompt, X_test_prompt, X_eval_prompt, y_true


def build_clean_and_perturbed_test(data_path: str):
    """
    è¿”å›ï¼š
        X_test_clean_prompt      : DataFrameï¼Œåˆ— ["text"]ï¼ˆCLEAN promptï¼‰
        y_true_clean             : list[str]
        X_test_perturbed_prompt  : DataFrameï¼Œåˆ— ["text"]ï¼ˆPERTURBED promptï¼‰
        y_true_perturbed         : list[str]
    """
    # 1ï¸âƒ£ å…ˆæ‹¿åˆ° **raw** çš„ clean test é›†ï¼ˆä¸åšä»»ä½•æ‰°åŠ¨ï¼‰
    X_train_raw, X_test_raw, X_eval_raw = load_split_raw_data(
        data_path,
        perturb_data=False,   # âœ… å¼ºåˆ¶ clean
    )
    # X_test_raw: åˆ— ["sentiment", "text"]

    # clean éƒ¨åˆ†ï¼šlabels + prompt
    y_true_clean = X_test_raw["sentiment"].tolist()
    X_test_clean_prompt = pd.DataFrame(
        X_test_raw.apply(generate_test_prompt, axis=1),
        columns=["text"]
    )

    # 2ï¸âƒ£ æ„é€ å¯¹åº”çš„æ‰°åŠ¨ç‰ˆæœ¬ï¼ˆåŒä¸€æ‰¹åŸå§‹å¥å­ï¼‰
    headlines = X_test_raw["text"].astype(str).tolist()

    pert_pairs_path = "./data/test_perturbations_text_pairs.csv"
    if not os.path.exists(pert_pairs_path):
        print("ğŸ§ª Generating test perturbation pairs ...")
        save_perturbation_text_pairs(
            headlines,
            filename="test_perturbations_text_pairs.csv"
        )

    pert_df = pd.read_csv(pert_pairs_path)  # æœŸæœ›æœ‰åˆ— ["orig", "pert"]

    # ç”¨ clean test çš„ label æ˜ å°„æ‰°åŠ¨æ ·æœ¬
    label_map = dict(zip(X_test_raw["text"], X_test_raw["sentiment"]))
    pert_df["sentiment"] = pert_df["orig"].map(label_map)

    # æ„é€ å’Œ raw test ç›¸ä¼¼çš„ DataFrameï¼š["text","sentiment"]
    X_test_pert_raw = pert_df.rename(columns={"pert": "text"})[["text", "sentiment"]].copy()

    # å¯¹æ‰°åŠ¨æ ·æœ¬ä¹Ÿåš prompt åŒ–
    X_test_perturbed_prompt = pd.DataFrame(
        X_test_pert_raw.apply(generate_test_prompt, axis=1),
        columns=["text"]
    )
    y_true_perturbed = X_test_pert_raw["sentiment"].tolist()

    return X_test_clean_prompt, y_true_clean, X_test_perturbed_prompt, y_true_perturbed

def build_clean_and_perturbed_pairs(data_path: str):
    """
    æ„é€  **ä¸€ä¸€æˆå¯¹** çš„ CLEAN / PERTURBED eval é›†ï¼Œç”¨äº Flip-Rate / Sym-KLã€‚

    è¿”å›ï¼š
        X_clean_prompt_pairs : DataFrameï¼Œåˆ— ["text"]ï¼ˆclean promptï¼Œå·² generate_test_promptï¼‰
        X_pert_prompt_pairs  : DataFrameï¼Œåˆ— ["text"]ï¼ˆperturbed promptï¼Œå·² generate_test_promptï¼‰
        y_true_pairs         : list[str]ï¼Œä¸ clean / perturbed æˆå¯¹å¯¹é½çš„ label
    """
    # 1ï¸âƒ£ è¿˜æ˜¯å…ˆæ‹¿ test split çš„ clean raw æ•°æ®
    X_train_raw, X_test_raw, X_eval_raw = load_split_raw_data(
        data_path,
        perturb_data=False,   # âœ… å¼ºåˆ¶ clean
    )
    # X_test_raw: ["sentiment", "text"]

    # 2ï¸âƒ£ è¯»å…¥ test å¯¹åº”çš„ perturb pairs
    pert_pairs_path = "./data/test_perturbations_text_pairs.csv"
    if not os.path.exists(pert_pairs_path):
        headlines = X_test_raw["text"].astype(str).tolist()
        print("ğŸ§ª Generating test perturbation pairs (for pair eval) ...")
        save_perturbation_text_pairs(
            headlines,
            filename="test_perturbations_text_pairs.csv"
        )

    pert_df = pd.read_csv(pert_pairs_path)  # æœŸæœ›æœ‰åˆ— ["orig", "pert"]

    # åªä¿ç•™é‚£äº›ç¡®å®åœ¨å½“å‰ test set é‡Œçš„ orig
    test_texts = set(X_test_raw["text"].astype(str).tolist())
    pert_df = pert_df[pert_df["orig"].astype(str).isin(test_texts)].copy()

    # å¦‚æœæŸä¸ª orig æœ‰å¤šæ¡ perturbï¼Œè¿™é‡Œå…ˆç®€å•æ‹¿ç¬¬ä¸€æ¡
    pert_df_unique = pert_df.drop_duplicates(subset=["orig"])

    # 3ï¸âƒ£ ç”¨ "text"/"orig" åš inner joinï¼Œè·å¾—ä¸€ä¸€é…å¯¹çš„å­é›†
    pairs = X_test_raw.merge(
        pert_df_unique,
        left_on="text",
        right_on="orig",
        how="inner",
    )
    # pairs ç°åœ¨åº”è¯¥åŒ…å«åˆ—ï¼š["text", "sentiment", "orig", "pert", ...]

    # 4ï¸âƒ£ æ„é€  clean / perturbed çš„ DataFrameï¼š["text","sentiment"]
    clean_pairs_raw = pairs[["text", "sentiment"]].copy()
    pert_pairs_raw  = pairs[["pert", "sentiment"]].rename(columns={"pert": "text"}).copy()

    # 5ï¸âƒ£ åŒæ ·åš prompt åŒ–ï¼Œä¿æŒå’Œä½ åŸ eval å®Œå…¨ä¸€è‡´çš„ prompt æ ¼å¼
    X_clean_prompt_pairs = pd.DataFrame(
        clean_pairs_raw.apply(generate_test_prompt, axis=1),
        columns=["text"]
    )
    X_pert_prompt_pairs = pd.DataFrame(
        pert_pairs_raw.apply(generate_test_prompt, axis=1),
        columns=["text"]
    )
    y_true_pairs = clean_pairs_raw["sentiment"].tolist()

    return X_clean_prompt_pairs, X_pert_prompt_pairs, y_true_pairs
